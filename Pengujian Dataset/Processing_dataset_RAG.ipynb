{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vagmXPFXEdNa"
      },
      "source": [
        "#Install Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4QYPuyumtYb0"
      },
      "outputs": [],
      "source": [
        "!pip install pymupdf langchain langchain-community chromadb sentence-transformers langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lqEqhoQu5X4H"
      },
      "outputs": [],
      "source": [
        "!pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OrIiMQkFESzk"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRS3Q_liEg7r"
      },
      "source": [
        "#Inizialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6QUqVmK7uPZU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rank_bm25 import BM25Okapi\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OZv4RRoufYo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDVJytMt_ZRk"
      },
      "source": [
        "#To make a vectordb/Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyyiMNVi2LAr"
      },
      "outputs": [],
      "source": [
        "# Define the parent directory containing subfolders with PDFs\n",
        "parent_dir = \"/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Introduction to AI\"\n",
        "\n",
        "# List all PDF file paths recursively\n",
        "pdf_files = []\n",
        "for root, _, files in os.walk(parent_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "# Load each PDF file as a single document\n",
        "intro_to_AI_docs = []\n",
        "for pdf_path in pdf_files:\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pages = loader.load()  # Load all pages\n",
        "\n",
        "    # Merge all pages into a single document\n",
        "    merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "\n",
        "    # Store as one document per file\n",
        "    intro_to_AI_docs.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Introduction to AI\"}\n",
        "    ))\n",
        "\n",
        "# Check the number of PDFs loaded (should match actual file count)\n",
        "print(f\"Total PDFs loaded: {len(intro_to_AI_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk41tTpS9G_0"
      },
      "outputs": [],
      "source": [
        "# Define the parent directory containing subfolders with PDFs\n",
        "parent_dir = \"/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Heuristic Search\"\n",
        "\n",
        "# List all PDF file paths recursively\n",
        "pdf_files = []\n",
        "for root, _, files in os.walk(parent_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "# Load each PDF file as a single document\n",
        "heuristic_docs = []\n",
        "for pdf_path in pdf_files:\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pages = loader.load()  # Load all pages\n",
        "\n",
        "    # Merge all pages into a single document\n",
        "    merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "\n",
        "    # Store as one document per file\n",
        "    heuristic_docs.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Heuristic Search\"}\n",
        "    ))\n",
        "\n",
        "# Check the number of PDFs loaded (should match actual file count)\n",
        "print(f\"Total PDFs loaded: {len(heuristic_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8dKhVz-9HaG"
      },
      "outputs": [],
      "source": [
        "# Define the parent directory containing subfolders with PDFs\n",
        "parent_dir = \"/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Rule based AI and Fuzzy Logic\"\n",
        "\n",
        "# List all PDF file paths recursively\n",
        "pdf_files = []\n",
        "for root, _, files in os.walk(parent_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "# Load each PDF file as a single document\n",
        "rule_base_fuzzy_docs = []\n",
        "for pdf_path in pdf_files:\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pages = loader.load()  # Load all pages\n",
        "\n",
        "    # Merge all pages into a single document\n",
        "    merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "\n",
        "    # Store as one document per file\n",
        "    rule_base_fuzzy_docs.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Rule based AI and Fuzzy Logic\"}\n",
        "    ))\n",
        "\n",
        "# Check the number of PDFs loaded (should match actual file count)\n",
        "print(f\"Total PDFs loaded: {len(rule_base_fuzzy_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GvacSWV9Hhs"
      },
      "outputs": [],
      "source": [
        "# Define the parent directory containing subfolders with PDFs\n",
        "parent_dir = \"/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Genetic Algorithm and Nature Inspired Algorithms\"\n",
        "\n",
        "# List all PDF file paths recursively\n",
        "pdf_files = []\n",
        "for root, _, files in os.walk(parent_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "# Load each PDF file as a single document\n",
        "GA_NIA_docs = []\n",
        "for pdf_path in pdf_files:\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pages = loader.load()  # Load all pages\n",
        "\n",
        "    # Merge all pages into a single document\n",
        "    merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "\n",
        "    # Store as one document per file\n",
        "    GA_NIA_docs.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Genetic Algorithm and Nature Inspired Algorithms\"}\n",
        "    ))\n",
        "\n",
        "# Check the number of PDFs loaded (should match actual file count)\n",
        "print(f\"Total PDFs loaded: {len(GA_NIA_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4lw1rdQ9HoD"
      },
      "outputs": [],
      "source": [
        "# Define the parent directory containing subfolders with PDFs\n",
        "parent_dir = \"/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Machine Learning\"\n",
        "\n",
        "# List all PDF file paths recursively\n",
        "pdf_files = []\n",
        "for root, _, files in os.walk(parent_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "# Load each PDF file as a single document\n",
        "ML_docs = []\n",
        "for pdf_path in pdf_files:\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pages = loader.load()  # Load all pages\n",
        "\n",
        "    # Merge all pages into a single document\n",
        "    merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "\n",
        "    ML_docs.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Machine Learning\"}\n",
        "    ))\n",
        "\n",
        "# Check the number of PDFs loaded (should match actual file count)\n",
        "print(f\"Total PDFs loaded: {len(ML_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZLRDIJp-vJk"
      },
      "outputs": [],
      "source": [
        "# Define the parent directory containing subfolders with PDFs\n",
        "parent_dir = \"/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Ensemble of Machine Learning\"\n",
        "\n",
        "# List all PDF file paths recursively\n",
        "pdf_files = []\n",
        "for root, _, files in os.walk(parent_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "# Load each PDF file as a single document\n",
        "ensembel_ML_docs = []\n",
        "for pdf_path in pdf_files:\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pages = loader.load()  # Load all pages\n",
        "\n",
        "    # Merge all pages into a single document\n",
        "    merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "\n",
        "    # Store as one document per file\n",
        "    ensembel_ML_docs.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Ensemble of Machine Learning\"}\n",
        "    ))\n",
        "\n",
        "# Check the number of PDFs loaded (should match actual file count)\n",
        "print(f\"Total PDFs loaded: {len(ensembel_ML_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrqKYtR4-veN"
      },
      "outputs": [],
      "source": [
        "# Define the parent directory containing subfolders with PDFs\n",
        "parent_dir = \"/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Neural Network, Deep Learning, and Generative AI\"\n",
        "\n",
        "# List all PDF file paths recursively\n",
        "pdf_files = []\n",
        "for root, _, files in os.walk(parent_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "# Load each PDF file as a single document\n",
        "NN_DL_Gen_AI_docs = []\n",
        "for pdf_path in pdf_files:\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pages = loader.load()  # Load all pages\n",
        "\n",
        "    # Merge all pages into a single document\n",
        "    merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "\n",
        "    # Store as one document per file\n",
        "    NN_DL_Gen_AI_docs.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Neural Network, Deep Learning, and Generative AI\"}\n",
        "    ))\n",
        "\n",
        "# Check the number of PDFs loaded (should match actual file count)\n",
        "print(f\"Total PDFs loaded: {len(NN_DL_Gen_AI_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvVLNJghMhn6"
      },
      "outputs": [],
      "source": [
        "books=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poFBV0uML0Rz"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader('/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Buku materi pembelajaran/Artificial-Intelligence-A-Modern-Approach-4th-Edition-1-compressed.pdf')\n",
        "pages = loader.load()  # Load all pages\n",
        "\n",
        "# Merge all pages into a single document\n",
        "merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "books.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Neural Network, Deep Learning, and Generative AI, Machine Learning, Ensemble of Machine Learning, Introduction to AI, Heuristic Search, Rule based AI and Fuzzy Logic, Genetic Algorithm and Nature Inspired Algorithms\"}\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20tPwaAsOFtL"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader('/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Buku materi pembelajaran/Hands_On_Machine_Learning_with_Scikit_Learn_and_TensorFlow.pdf')\n",
        "pages = loader.load()  # Load all pages\n",
        "\n",
        "# Merge all pages into a single document\n",
        "merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "books.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Neural Network, Deep Learning, and Generative AI, Machine Learning, Ensemble of Machine Learning\"}\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAOIVMccOcb-"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader('/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Buku materi pembelajaran/Genetic Algorithms with Python by Eyal Wirsansky .pdf')\n",
        "pages = loader.load()  # Load all pages\n",
        "\n",
        "# Merge all pages into a single document\n",
        "merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "books.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Genetic Algorithm and Nature Inspired Algorithms\"}\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRWNT35wRNh6"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader('/content/drive/MyDrive/Skripsi_C14210098/Dataset RAG/Buku materi pembelajaran/a-machine-learning-artificial-intelligence-approach-to-institutional-effectiveness-in-higher-education-1nbsped-9781789738995-9781789739008.pdf')\n",
        "pages = loader.load()  # Load all pages\n",
        "\n",
        "# Merge all pages into a single document\n",
        "merged_text = \"\\n\".join([page.page_content for page in pages])\n",
        "books.append(Document(\n",
        "        page_content=merged_text,\n",
        "        metadata={\"source\": pdf_path, \"module\": \"Neural Network, Deep Learning, and Generative AI, Machine Learning\"}\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upGk9obqT0YU"
      },
      "outputs": [],
      "source": [
        "print(f\"Total PDFs loaded: {len(books)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUKof1PlQIIy"
      },
      "outputs": [],
      "source": [
        "# Remove '\\n' from page_content\n",
        "for doc in intro_to_AI_docs:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "for doc in heuristic_docs:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "for doc in rule_base_fuzzy_docs:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "for doc in GA_NIA_docs:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "for doc in ML_docs:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "for doc in ensembel_ML_docs:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "for doc in NN_DL_Gen_AI_docs:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "for doc in books:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg74HyRsRzea"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G28i4hdXwvK"
      },
      "outputs": [],
      "source": [
        "intro_to_AI_chunks = text_splitter.split_documents(intro_to_AI_docs)\n",
        "heuristic_chunks = text_splitter.split_documents(heuristic_docs)\n",
        "rule_base_fuzzy_chunks = text_splitter.split_documents(rule_base_fuzzy_docs)\n",
        "GA_NIA_chunks = text_splitter.split_documents(GA_NIA_docs)\n",
        "ML_chunks = text_splitter.split_documents(ML_docs)\n",
        "ensembel_ML_chunks = text_splitter.split_documents(ensembel_ML_docs)\n",
        "NN_DL_Gen_AI_chunks = text_splitter.split_documents(NN_DL_Gen_AI_docs)\n",
        "books_chunks = text_splitter.split_documents(books)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYsN1TcGRzea"
      },
      "outputs": [],
      "source": [
        "all_chunks = intro_to_AI_chunks + heuristic_chunks + rule_base_fuzzy_chunks + GA_NIA_chunks + ML_chunks + ensembel_ML_chunks + NN_DL_Gen_AI_chunks+books_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCrVolTPfIFl"
      },
      "outputs": [],
      "source": [
        "len(all_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUZog4i55cb5"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/content/drive/MyDrive/Skripsi_C14210098/5000_DB'\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4NBOGDB5hq2"
      },
      "outputs": [],
      "source": [
        "#To make vectordb\n",
        "vectordb = Chroma.from_documents(documents=all_chunks,\n",
        "                                 embedding=hf,\n",
        "                                 persist_directory=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iCqPo-l-bkX"
      },
      "outputs": [],
      "source": [
        "len(vectordb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8IcBm-sHEXK"
      },
      "source": [
        "#Pengujian dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvsL_wWlHLXy"
      },
      "source": [
        "##Load Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c5MFxk-MKtyJ"
      },
      "outputs": [],
      "source": [
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JczChMnMKrn-"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/content/drive/MyDrive/Skripsi_C14210098/DB_2000'\n",
        "vectordb_2000 = Chroma(embedding_function=hf, persist_directory=persist_directory)\n",
        "vectordb_2000.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5H-W3x0aK8kx"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/content/drive/MyDrive/Skripsi_C14210098/DB_3000'\n",
        "vectordb_3000 = Chroma(embedding_function=hf, persist_directory=persist_directory)\n",
        "vectordb_3000.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "REBJx3q_K84C"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/content/drive/MyDrive/Skripsi_C14210098/DB_4000'\n",
        "vectordb_4000 = Chroma(embedding_function=hf, persist_directory=persist_directory)\n",
        "vectordb_4000.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9m_7AI9FK9Lf"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/content/drive/MyDrive/Skripsi_C14210098/5000_DB'\n",
        "vectordb_5000 = Chroma(embedding_function=hf, persist_directory=persist_directory)\n",
        "vectordb_5000.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c5MBGeLKK9Sx"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/content/drive/MyDrive/Skripsi_C14210098/DB_6000'\n",
        "vectordb_6000 = Chroma(embedding_function=hf, persist_directory=persist_directory)\n",
        "vectordb_6000.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IKT0y53WdBRy"
      },
      "outputs": [],
      "source": [
        "print(f\"Length of vectordb_2000: {len(vectordb_2000)}\")\n",
        "print(f\"Length of vectordb_3000: {len(vectordb_3000)}\")\n",
        "print(f\"Length of vectordb_4000: {len(vectordb_4000)}\")\n",
        "print(f\"Length of vectordb_5000: {len(vectordb_5000)}\")\n",
        "print(f\"Length of vectordb_6000: {len(vectordb_6000)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "71lAWpvlTGA8"
      },
      "outputs": [],
      "source": [
        "print(f\"Length of vectordb_5000: {len(vectordb_5000)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3GbgnWgCpPw"
      },
      "source": [
        "##Reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MozUQpr_ClHq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "reranker_model_name= \"BAAI/bge-reranker-base\"\n",
        "reranker_tokenizer = AutoTokenizer.from_pretrained(reranker_model_name)\n",
        "reranker_model = AutoModelForSequenceClassification.from_pretrained(reranker_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ2Q6XkJCtuA"
      },
      "outputs": [],
      "source": [
        "def rerank_documents(docs, query, top_k):\n",
        "    \"\"\"\n",
        "    Reranks retrieved documents using bge-reranker-base.\n",
        "\n",
        "    Parameters:\n",
        "        docs (List[Document]): List of retrieved documents.\n",
        "        query (str): The original query.\n",
        "        top_k (int): Number of top-ranked documents to return.\n",
        "\n",
        "    Returns:\n",
        "        List[Document]: Reranked list of top_k documents.\n",
        "    \"\"\"\n",
        "    if not docs:\n",
        "        return []\n",
        "\n",
        "    # Prepare inputs for reranking\n",
        "    inputs = [(query, doc.page_content) for doc in docs]\n",
        "\n",
        "    # Tokenize inputs\n",
        "    tokenized_inputs = reranker_tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Get output from reranker model\n",
        "    with torch.no_grad():\n",
        "        outputs = reranker_model(**tokenized_inputs)\n",
        "\n",
        "    # Extract relevance scores from `pooler_output`\n",
        "    scores = outputs.logits.squeeze().tolist()\n",
        "\n",
        "    # Combine documents and scores, then sort by score (descending)\n",
        "    ranked_docs = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return top_k documents\n",
        "    return [doc for doc, _ in ranked_docs[:top_k]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YhrPiQIdUeT"
      },
      "source": [
        "##Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLYI-r_7WGWj"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-id\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-id\")\n",
        "def translate(text):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "  outputs = model.generate(**inputs)\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EFbM_bnmdYe2"
      },
      "outputs": [],
      "source": [
        "def retriever(query, chroma_db, module_name, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Retrieves relevant documents using an ensemble of BM25 and Chroma retrievers,\n",
        "    then reranks them using bge-reranker-base.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The user query.\n",
        "        chroma_db (Chroma): The Chroma database instance.\n",
        "        module_name (str): The module name to filter documents.\n",
        "        top_k (int): Number of top-ranked documents to return.\n",
        "\n",
        "    Returns:\n",
        "        List[Document]: Final reranked documents.\n",
        "    \"\"\"\n",
        "    # Get all documents from ChromaDB\n",
        "    all_data = chroma_db.get()\n",
        "\n",
        "    # Filter documents by module\n",
        "    filtered_docs = [\n",
        "        Document(page_content=text, metadata=meta)\n",
        "        for text, meta in zip(all_data[\"documents\"], all_data[\"metadatas\"])\n",
        "        if meta.get(\"module\") == module_name\n",
        "    ]\n",
        "\n",
        "    if not filtered_docs:\n",
        "        return []\n",
        "\n",
        "    # BM25 Retriever (lexical search) with filtered documents\n",
        "    bm25_retriever = BM25Retriever.from_documents(filtered_docs)\n",
        "    bm25_retriever.k = 5  # Number of top results to retrieve\n",
        "\n",
        "    # Chroma Retriever (vector search)\n",
        "    chroma_retriever = chroma_db.as_retriever(search_kwargs={'k': 5, 'filter': {'module': module_name}})\n",
        "\n",
        "    # Ensemble Retriever (combining both)\n",
        "    ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[alpha, 1-alpha])\n",
        "\n",
        "    # Retrieve documents\n",
        "    docs = ensemble_retriever.invoke(query)\n",
        "\n",
        "    # Rerank the retrieved documents using the previous rerank_documents function\n",
        "    return rerank_documents(docs, query, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jpeybV5PTtD_"
      },
      "outputs": [],
      "source": [
        "docs = retriever(\"What is Machine Learning?\", vectordb_5000,\"Machine Learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUdX03WZYE5F"
      },
      "outputs": [],
      "source": [
        "print(\"ENG:\")\n",
        "for doc in docs:\n",
        "  print(\"- \", doc.page_content, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWQPcG9rX02J"
      },
      "outputs": [],
      "source": [
        "print(\"ID:\")\n",
        "for doc in docs:\n",
        "  doc.page_content = translate(doc.page_content)\n",
        "  print(\"- \", doc.page_content, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5EAvoMmkUso"
      },
      "source": [
        "## FINAL Pengujian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsrvqPBPfV6_"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def evaluate_all_metrics_from_file(csv_path, chroma_db, queries, module_names, alpha=0.5,\n",
        "                                   relevance_col=\"Nilai/Ranking (0-3)\", query_col=\"Query\", doc_col=\"Documents content\", k=5):\n",
        "    \"\"\"\n",
        "    Evaluasi retrieval dari file CSV: NDCG, cosine similarity, dan waktu retrieval per query.\n",
        "\n",
        "    Parameters:\n",
        "        csv_path (str): Path ke file CSV.\n",
        "        chroma_db: ChromaDB instance.\n",
        "        module_name (str): Filter modul dokumen.\n",
        "        alpha (float): Bobot cosine similarity (BM25 = 1 - alpha).\n",
        "        k (int): Top-k untuk evaluasi NDCG.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Tabel NDCG per query. Print juga rata-rata semua metrik.\n",
        "    \"\"\"\n",
        "    # Load CSV & inisialisasi\n",
        "    df = pd.read_csv(csv_path)\n",
        "    queries = df[query_col].unique().tolist()\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    results = []\n",
        "    total_cosine_values = []\n",
        "    total_retrieval_time = []\n",
        "\n",
        "    for query in queries:\n",
        "        group = df[df[query_col] == query]\n",
        "        if group.empty:\n",
        "            continue\n",
        "\n",
        "        docs = group[doc_col].tolist()\n",
        "        ground_truth = group[relevance_col].tolist()\n",
        "\n",
        "        # BM25 lexical score\n",
        "        tokenized_docs = [doc.lower().split() for doc in docs]\n",
        "        tokenized_query = query.lower().split()\n",
        "        bm25 = BM25Okapi(tokenized_docs)\n",
        "        bm25_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "        # Cosine score (MiniLM)\n",
        "        query_embedding = model.encode([query])\n",
        "        doc_embeddings = model.encode(docs)\n",
        "        cosine_scores = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
        "        total_cosine_values.extend(cosine_scores)\n",
        "\n",
        "        # Min-max normalization\n",
        "        def normalize(scores):\n",
        "            min_s, max_s = min(scores), max(scores)\n",
        "            return [(s - min_s) / (max_s - min_s) if max_s != min_s else 0.5 for s in scores]\n",
        "\n",
        "        bm25_norm = normalize(bm25_scores)\n",
        "        cosine_norm = normalize(cosine_scores)\n",
        "        combined = [alpha * c + (1 - alpha) * b for c, b in zip(cosine_norm, bm25_norm)]\n",
        "\n",
        "        # Hitung NDCG\n",
        "        ndcg = ndcg_score([ground_truth], [combined], k=k)\n",
        "        results.append({\"Query\": query, \"NDCG\": ndcg})\n",
        "\n",
        "        # Hitung retrieval time dari retriever milikmu\n",
        "        for query, module_name in zip(queries, module_names):\n",
        "          start = time.time()\n",
        "          _ = retriever(query, chroma_db, module_name, alpha=alpha)\n",
        "          end = time.time()\n",
        "          total_retrieval_time.append(end - start)\n",
        "\n",
        "    # Buat DataFrame hasil evaluasi\n",
        "    ndcg_df = pd.DataFrame(results)\n",
        "    avg_ndcg = ndcg_df[\"NDCG\"].mean()\n",
        "    avg_cosine = sum(total_cosine_values) / len(total_cosine_values) if total_cosine_values else 0.0\n",
        "    avg_retrieval = sum(total_retrieval_time) / len(total_retrieval_time) if total_retrieval_time else 0.0\n",
        "\n",
        "    # Cetak summary\n",
        "    print(f\"\\n📄 File: {csv_path}\")\n",
        "    print(f\"🔢 Average NDCG across all queries: {avg_ndcg:.4f}\")\n",
        "    print(f\"📏 Average Cosine Similarity: {avg_cosine:.4f}\")\n",
        "    print(f\"⏱️  Average Retrieval Time: {avg_retrieval:.4f} seconds\\n\")\n",
        "\n",
        "    return ndcg_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoGB4CtQzFX0"
      },
      "outputs": [],
      "source": [
        "queries=[\"What is the definition of Unsupervised Learning?\",\n",
        "         \"What are the main advantages of Particle Swarm Optimization compared to traditional optimization algorithms?\",\n",
        "         \"How is AI used in everyday life?\",\n",
        "         \"What are some common heuristic search algorithms?\",\n",
        "         \"What is an artificial neural network (ANN)?\"]\n",
        "module_names=[\"Supervised, Unsupervised and Reinforcement Learning\",\n",
        "              \"Genetic Algorithm and Nature Inspired Algorithms\",\n",
        "              \"Introduction to AI\",\n",
        "              \"Heuristic Search\",\n",
        "              \"Neural Network, Deep Learning, and Generative AI\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX4IzvWNrNi4"
      },
      "outputs": [],
      "source": [
        "evaluate_all_metrics_from_file(\"/content/drive/MyDrive/Skripsi_C14210098/Ranking NDCG/Ranking document NDCG - DB_2000.csv\", vectordb_2000, queries, module_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv1k860H2M52"
      },
      "outputs": [],
      "source": [
        "evaluate_all_metrics_from_file(\"/content/drive/MyDrive/Skripsi_C14210098/Ranking NDCG/Ranking document NDCG - DB_3000.csv\", vectordb_2000, queries, module_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtTBr9sQ2P-8"
      },
      "outputs": [],
      "source": [
        "evaluate_all_metrics_from_file(\"/content/drive/MyDrive/Skripsi_C14210098/Ranking NDCG/Ranking document NDCG - DB_4000.csv\", vectordb_2000, queries, module_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF_iRbxC2QR8"
      },
      "outputs": [],
      "source": [
        "evaluate_all_metrics_from_file(\"/content/drive/MyDrive/Skripsi_C14210098/Ranking NDCG/Ranking document NDCG - DB_5000.csv\", vectordb_2000, queries, module_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZsg38TM2Qmh"
      },
      "outputs": [],
      "source": [
        "evaluate_all_metrics_from_file(\"/content/drive/MyDrive/Skripsi_C14210098/Ranking NDCG/Ranking document NDCG - DB_6000.csv\", vectordb_2000, queries, module_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WvsL_wWlHLXy",
        "r3GbgnWgCpPw",
        "2YhrPiQIdUeT",
        "_f6H7frn1ooJ"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}